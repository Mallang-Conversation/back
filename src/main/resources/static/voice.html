<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
  <title>실시간 음성 대화</title>
</head>
<body>
<h1>실시간 음성 대화</h1>

<!-- 대화 관련 버튼 -->
<button id="conversationStartBtn">대화 시작</button>
<button id="conversationEndBtn" disabled>대화 종료</button>
<br><br>
<!-- 녹음 관련 버튼 (웹소켓 연결되어야 활성화됨) -->
<button id="recordStartBtn" disabled>녹음 시작</button>
<button id="recordStopBtn" disabled>녹음 중지</button>

<script>
  // 웹소켓 및 오디오 관련 변수 선언
  let ws;
  let audioContext;
  let processor;
  let input;
  let mediaStream;
  let audioDataBuffer = []; // Int16Array 조각들을 누적

  // 버튼 요소
  const conversationStartBtn = document.getElementById("conversationStartBtn");
  const conversationEndBtn = document.getElementById("conversationEndBtn");
  const recordStartBtn = document.getElementById("recordStartBtn");
  const recordStopBtn = document.getElementById("recordStopBtn");

  // 대화 시작 버튼 클릭: 웹소켓(ws://localhost:8081/ws/chat) 연결
  conversationStartBtn.addEventListener("click", () => {
    ws = new WebSocket("ws://localhost:8081/ws/chat");
    ws.binaryType = "arraybuffer";
    ws.onopen = () => {
      console.log("대화용 WebSocket 연결 성공");
      // 대화 연결이 성공하면 녹음을 시작할 수 있도록 녹음 버튼 활성화
      recordStartBtn.disabled = false;
    };
    ws.onmessage = (event) => {
      if (event.data.startsWith("SESSION_ID:")) {
        const sessionId = event.data.split(":")[1]; // 세션 ID 추출
        console.log("세션 ID:", sessionId);
        window.sessionId = sessionId; // 전역 변수로 저장
      }
    };
    ws.onerror = (err) => {
      console.error("대화용 WebSocket 에러:", err);
    };
    ws.onclose = () => {
      console.log("대화용 WebSocket 연결 종료");
      // 연결이 끊기면 녹음 시작 버튼도 비활성화
      recordStartBtn.disabled = true;
    };

    conversationStartBtn.disabled = true;
    conversationEndBtn.disabled = false;
  });

  // 대화 종료 버튼 클릭: 웹소켓 연결 종료
  conversationEndBtn.addEventListener("click", () => {
    if (ws && ws.readyState === WebSocket.OPEN) {
      ws.close();
    }
    conversationStartBtn.disabled = false;
    conversationEndBtn.disabled = true;
    // 녹음 중이 아니라면 녹음 시작 버튼도 비활성화
    recordStartBtn.disabled = true;
  });

  // 녹음 시작 버튼 클릭: 마이크 접근 및 PCM 데이터 수집 시작
  recordStartBtn.addEventListener("click", async () => {
    // 웹소켓이 연결되어 있지 않으면 녹음을 시작하지 않음
    if (!ws || ws.readyState !== WebSocket.OPEN) {
      alert("대화가 연결되어 있어야 녹음을 시작할 수 있습니다.");
      return;
    }

    try {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      input = audioContext.createMediaStreamSource(mediaStream);

      // ScriptProcessorNode 생성 (버퍼 사이즈: 4096, 채널 수: 1)
      processor = audioContext.createScriptProcessor(4096, 1, 1);
      input.connect(processor);
      // processor를 destination에 연결하면 소리가 나므로 여기서는 연결하지 않습니다.
      processor.connect(audioContext.destination);

      processor.onaudioprocess = (e) => {
        // 입력 채널의 데이터를 Float32Array로 추출 (정규화된 -1 ~ 1 값)
        const channelData = e.inputBuffer.getChannelData(0);
        // Float32Array 데이터를 Int16Array(PCM)로 변환
        const pcmChunk = floatTo16BitPCM(channelData);
        // 누적 버퍼에 저장
        audioDataBuffer.push(pcmChunk);

        // 웹소켓을 통해 현재 청크 전송 (raw PCM 데이터)
        if (ws.readyState === WebSocket.OPEN) {
          ws.send(pcmChunk.buffer);
          console.log("전송한 PCM 데이터 크기:", pcmChunk.byteLength, "바이트");
        }
      };

      console.log("PCM 데이터 수집 시작");
      recordStartBtn.disabled = true;
      recordStopBtn.disabled = false;
    } catch (err) {
      console.error("마이크 접근 또는 AudioContext 생성 에러:", err);
    }
  });

  // 녹음 중지 버튼 클릭: 녹음을 중지하고 WAV 파일 생성 후 다운로드
  recordStopBtn.addEventListener("click", () => {
    // ScriptProcessorNode 및 AudioContext 정리
    if (processor) {
      processor.disconnect();
      if (input) {
        input.disconnect();
      }
      processor.onaudioprocess = null;
    }
    if (audioContext) {
      audioContext.close();
    }
    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
    }

    // 누적된 PCM 데이터를 하나의 Int16Array로 병합
    const mergedPCM = mergeBuffers(audioDataBuffer);
    // (예시) 기본 샘플레이트 44100Hz, 모노, 16비트로 WAV Blob 생성
    const wavBlob = createWavBlob(mergedPCM, 44100, 1, 16);
    console.log("WAV 파일 Blob 생성됨:", wavBlob);

    // 다운로드 링크 생성 (또는 서버 전송)
    const url = URL.createObjectURL(wavBlob);
    const a = document.createElement("a");
    a.style.display = "none";
    a.href = url;
    a.download = `${window.sessionId}.wav`;
    document.body.appendChild(a);
    a.click();
    window.URL.revokeObjectURL(url);

    // 녹음 데이터 버퍼 초기화 및 버튼 상태 업데이트
    audioDataBuffer = [];
    recordStartBtn.disabled = false;
    recordStopBtn.disabled = true;
  });

  // Float32Array 데이터를 Int16Array (PCM 데이터)로 변환하는 함수
  function floatTo16BitPCM(float32Array) {
    const len = float32Array.length;
    const int16Array = new Int16Array(len);
    for (let i = 0; i < len; i++) {
      let s = Math.max(-1, Math.min(1, float32Array[i])); // 클램핑
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return int16Array;
  }

  // 누적된 Int16Array 조각들을 하나로 합치는 함수
  function mergeBuffers(buffers) {
    let totalLength = buffers.reduce((acc, curr) => acc + curr.length, 0);
    const result = new Int16Array(totalLength);
    let offset = 0;
    buffers.forEach(buffer => {
      result.set(buffer, offset);
      offset += buffer.length;
    });
    return result;
  }

  // WAV Blob 생성 함수 (PCM 데이터에 WAV 헤더를 붙여 Blob으로 만듦)
  function createWavBlob(pcmData, sampleRate, channels, bitsPerSample) {
    const header = new ArrayBuffer(44);
    const view = new DataView(header);

    // RIFF 식별자 "RIFF"
    writeString(view, 0, 'RIFF');
    // 전체 파일 크기 (pcmData.byteLength + 36)
    view.setUint32(4, 36 + pcmData.byteLength * (bitsPerSample / 8), true);
    // 파일 포맷 "WAVE"
    writeString(view, 8, 'WAVE');
    // fmt 청크
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);             // Subchunk1Size (16 for PCM)
    view.setUint16(20, 1, true);              // AudioFormat (1 = PCM)
    view.setUint16(22, channels, true);       // NumChannels
    view.setUint32(24, sampleRate, true);     // SampleRate
    view.setUint32(28, sampleRate * channels * bitsPerSample / 8, true); // ByteRate
    view.setUint16(32, channels * bitsPerSample / 8, true); // BlockAlign
    view.setUint16(34, bitsPerSample, true);  // BitsPerSample
    // data 청크
    writeString(view, 36, 'data');
    view.setUint32(40, pcmData.byteLength * (bitsPerSample / 8), true);

    // PCM 데이터를 ArrayBuffer로 변환
    const pcmBuffer = pcmData.buffer;
    // WAV 파일 전체 데이터 (헤더 + PCM 데이터)
    const wavBuffer = new Uint8Array(header.byteLength + pcmBuffer.byteLength);
    wavBuffer.set(new Uint8Array(header), 0);
    wavBuffer.set(new Uint8Array(pcmBuffer), header.byteLength);

    return new Blob([wavBuffer], { type: 'audio/wav' });
  }

  // DataView에 문자열을 기록하는 헬퍼 함수
  function writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }
</script>
</body>
</html>